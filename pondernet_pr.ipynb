{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMeq/DSQCUwBQXe4k13koto",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwn-w/python/blob/main/pondernet_pr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7x2JrDu9KHx"
      },
      "source": [
        "from typing import Tuple"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHffJ6T89bCh"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb00yix2-L1X",
        "outputId": "99fee09b-1b88-4572-a6e2-172786b7df1d"
      },
      "source": [
        "pip install Module"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Module\n",
            "  Downloading module-0.0.4-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: Module\n",
            "Successfully installed Module-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEYT52CR_EKo",
        "outputId": "6a14354a-4fbb-4c60-c931-7c36e7ee181e"
      },
      "source": [
        "pip install labml-helpers"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting labml-helpers\n",
            "  Downloading labml_helpers-0.4.82-py3-none-any.whl (18 kB)\n",
            "Collecting labml>=0.4.129\n",
            "  Downloading labml-0.4.132-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from labml-helpers) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.129->labml-helpers) (1.19.5)\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 22.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from labml>=0.4.129->labml-helpers) (3.13)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython->labml>=0.4.129->labml-helpers) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython, labml, labml-helpers\n",
            "Successfully installed gitdb-4.0.7 gitpython-3.1.18 labml-0.4.132 labml-helpers-0.4.82 smmap-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8wqsqFE913o"
      },
      "source": [
        "from labml_helpers.module import Module"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FumaXNM__hZ5"
      },
      "source": [
        "**PonderNet with GRU for Parity Task**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX5nizU_931G"
      },
      "source": [
        "class ParityPonderGRU(Module):\n",
        "  def __init__(self, n_elems: int, n_hidden: int, max_steps: int):\n",
        "    super().__init__()\n",
        "    self.max_steps = max_steps\n",
        "    self.n_hidden = n_hidden\n",
        "\n",
        "    self.gru = nn.GRUCell(n_elems, n_hidden)\n",
        "\n",
        "    self.output_layer = nn.Linear(n_hidden, 1)\n",
        "\n",
        "    self.lambda_layer = nn.Linear(n_hidden, 1)\n",
        "    self.lambda_prob = nn.Sigmoid()\n",
        "\n",
        "    self.is_halt = False\n",
        "\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    batch_size = x.shape[0]\n",
        "\n",
        "    h = x.new_zeros((x.shape[0], self.n_hidden))\n",
        "    h = self.gru(x, h)\n",
        "\n",
        "    p = []\n",
        "    y = []\n",
        "\n",
        "    un_halted_prob = h.new_ones((batch_size,))\n",
        "\n",
        "    halted = h.new_zeros((batch_size,))\n",
        "\n",
        "    p_m = h.new_zeros((batch_size,))\n",
        "    y_m = h.new_zeros((batch_size,))\n",
        "\n",
        "    for n in range(1, self.max_steps + 1):\n",
        "      if n == self.max_steps:\n",
        "        lambda_n = h.new_ones(h.shape[0])\n",
        "      else:\n",
        "        lambda_n = self.lambda_prob(self.lambda_layer(h))[:, 0]\n",
        "\n",
        "      y_n = self.output_layer(h)[:, 0]\n",
        "\n",
        "      p_n = un_halted_prob * lambda_n\n",
        "\n",
        "      un_halted_prob = un_halted_prob * (1 - lambda_n)\n",
        "      halt = torch.bernoulli(lambda_n) * (1 - halted)\n",
        "\n",
        "      p.append(p_n)\n",
        "      y.append(y_n)\n",
        "\n",
        "      p_m = p_m * (1 - halt) + p_n * halt\n",
        "      y_m = y_m * (1 - halt) + y_n * halt\n",
        "\n",
        "      halted = halted + halt\n",
        "\n",
        "      h = self.gru(x, h)\n",
        "\n",
        "      if self.is_halt and halted.sum() == batch_size:\n",
        "        break\n",
        "\n",
        "      return torch.stack(p), torch.stack(y), p_m, y_m"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFL1sjwOBTcm"
      },
      "source": [
        "class ReconstructionLoss(Module):\n",
        "  def __init__(self, loss_func: nn.Module):\n",
        "    super().__init__()\n",
        "    self.loss_func = loss_func\n",
        "\n",
        "\n",
        "  def forward(self, p: torch.Tensor, y_hat: torch.Tensor, y: torch.Tensor):\n",
        "    total_loss = p.new_tensor(0.)\n",
        "    for n in range(p.shape[0]):\n",
        "      loss = (p[n] * self.loss_func(y_hat[n], y)).mean()\n",
        "      total_loss = total_loss + loss\n",
        "    return total_loss"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFEkuy9xBn25"
      },
      "source": [
        "class RegularizationLoss(Module):\n",
        "  def __init__(self, lambda_p: float, max_steps: int = 1_000):\n",
        "    super().__init__()\n",
        "    p_g = torch.zeros((max_steps,))\n",
        "    not_halted = 1.\n",
        "    \n",
        "    for k in range(max_steps):\n",
        "      p_g[k] = not_halted * lambda_p\n",
        "      not_halted = not_halted * (1 - lambda_p)\n",
        "      \n",
        "    self.p_g = nn.Parameter(p_g, requires_grad=False)\n",
        "    self.kl_div = nn.KLDivLoss(reduction='batchmean')\n",
        "    \n",
        "    \n",
        "  def forward(self, p: torch.Tensor):\n",
        "    p = p.transpose(0, 1)\n",
        "    p_g = self.p_g[None, :p.shape[1]].expand_as(p)\n",
        "    return self.kl_div(p.log(), p_g)"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}